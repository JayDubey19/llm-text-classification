# LLM-Powered Text Classification API

A minimal **FastAPI-based API** for classifying text into categories such as **toxic**, **spam**, and **safe**, powered by a Hugging Face transformer model.  

This project was built as part of an assignment to demonstrate:
- LLM-powered content moderation
- Prompt engineering
- Feedback loop for continuous improvement
- API metrics & evaluation harness

---

## ğŸš€ Features
- **POST /classify** â†’ Classify input text (`toxic`, `spam`, `safe`)
- **POST /feedback** â†’ Store feedback for retraining/evaluation
- **GET /metrics** â†’ Track total requests, class distribution, feedback, latency
- **GET /healthz** â†’ Health check
- **Prompt Engineering** â†’ Includes baseline and improved prompts
- **Evaluation Harness** â†’ Accuracy, Precision, Recall, and F1 on small dataset

---

## ğŸ“‚ Project Structure
```
.
â”œâ”€ app/
â”‚  â”œâ”€ main.py               # FastAPI entrypoint
â”‚  â”œâ”€ routes/               # API route handlers
â”‚  â”œâ”€ services/             # Hugging Face integration
â”‚  â”œâ”€ prompts/              # Baseline & improved prompts
â”‚  â””â”€ telemetry/            # Metrics collection
â”œâ”€ eval/
â”‚  â”œâ”€ dataset.jsonl         # Small evaluation dataset
â”‚  â””â”€ run.py                # Evaluation script
â”œâ”€ tests/
â”‚  â””â”€ test_api.py           # Basic API tests
â”œâ”€ requirements.txt         # Dependencies
â””â”€ README.md                # Documentation
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the repo
```bash
git clone https://github.com/YOUR-USERNAME/llm-text-classification.git
cd llm-text-classification
```

### 2. Create and activate virtual environment
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Run the API
```bash
uvicorn app.main:app --reload
```

Visit ğŸ‘‰ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs) to test endpoints in Swagger UI.  

---

## ğŸ› ï¸ API Usage

### ğŸ”¹ Health Check
```bash
GET /healthz
```
Response:
```json
{"status": "ok"}
```

### ğŸ”¹ Classify Text
```bash
POST /classify
{
  "text": "I hate you"
}
```
Response:
```json
{
  "class": "toxic",
  "confidence": 0.95,
  "prompt_used": "You are a helpful moderation assistant...\nText: I hate you\nAnswer:",
  "latency_ms": 120
}
```

### ğŸ”¹ Send Feedback
```bash
POST /feedback
{
  "text": "I hate you",
  "predicted": "toxic",
  "correct": "toxic"
}
```

### ğŸ”¹ Metrics
```bash
GET /metrics
```
Response example:
```json
{
  "total_requests": 3,
  "class_distribution": {"toxic": 2, "safe": 1},
  "feedback_counts": {"positive": 1, "negative": 0},
  "latency": {"avg_ms": 150, "p95_ms": 200}
}
```

---

## ğŸ§  Prompt Engineering

- **Baseline Prompt**
```text
Classify the following text into toxic, spam, or safe:
{text}
```

- **Improved Prompt**
```text
You are a helpful moderation assistant.
Analyze the user text carefully and classify it as one of:
- toxic (offensive or hateful)
- spam (irrelevant or promotional)
- safe (harmless)

Text: {text}
Answer:
```

**Choice Rationale:**  
- Baseline â†’ zero-shot, minimal instruction.  
- Improved â†’ role-based, structured categories, improves accuracy.  

---

## ğŸ“Š Evaluation

Dataset: [`eval/dataset.jsonl`](eval/dataset.jsonl) (~20â€“30 labeled examples).  

Run evaluation:
```bash
python -m eval.run
```

Metrics reported:
- Accuracy
- Precision
- Recall
- F1-score

---

## âš–ï¸ Design Trade-offs & Limitations
- **In-memory feedback** â†’ resets on server restart (could be persisted in SQLite/JSON for production).
- **Small dataset** â†’ only for demonstration, not robust training.
- **CPU inference only** â†’ slower on large models, but works for assignment/demo.
- **Limited categories** â†’ only `toxic`, `spam`, `safe`; can be expanded.

---

## ğŸŒ (Optional) Deployment
This API can be deployed to **Render**, **Railway**, or **Fly.io**.  
Start Command:
```bash
uvicorn app.main:app --host 0.0.0.0 --port 10000
```

---

## ğŸ§ª Running Tests

This project includes basic tests for all endpoints using **pytest**.

### Run Tests
From the project root:
```bash
pytest
```

On Windows PowerShell, if you face `ModuleNotFoundError`, set `PYTHONPATH` explicitly:
```powershell
$env:PYTHONPATH="."; pytest
```

### Example Output
```
collected 4 items

tests/test_api.py ....                                                       [100%]

4 passed in 22.6s
```

âœ… This confirms that `/healthz`, `/classify`, `/feedback`, and `/metrics` are all working as expected.

---

## âœ… Deliverables
- [x] FastAPI app with required endpoints  
- [x] Prompt library with baseline & improved prompts  
- [x] Feedback persistence  
- [x] Metrics endpoint  
- [x] Evaluation harness with dataset  
- [x] README with setup, usage, prompts, and evaluation  
- [x] Basic tests for endpoints  

---
